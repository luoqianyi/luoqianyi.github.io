# Hadoop大数据技术

### 1.大数据时代

###### 三次信息化浪潮的标志？

第一次：PC

第二次：互联网

第三次：大数据、云计算、物联网

### 2.大数据特点

4V：数据量大、数据类型多、处理速度快、价值密度低

### 3.大数据对思维方式的重要影响？

1. 全样而非抽样

   在过去,数据存储和处理能力有限，所以在科学分析中一般采用抽样的方法，而现在，有了大数据技术的支持，科学分析可以直接针对全样数据进行分析而不是抽样数据；

2. 效率而非精确

   在科学分析中如果采用抽样分析，则分析需要做到精确，否则分析后的结果误差就会被放大，为了保证误差在可控范围内，就必须确保分析结果的精确性，因此传统的分析往往更注重算法的精确性，算法的效率则在其次；而大数据时代中的科学分析采用全样分析，就不存在抽样分析过程误差被放大的情况，因此数据分析的效率就成为了关注的核心；

3. 相关而非因果

   过去，数据分析的目的，一是为了解释事物背后的发展机理，二是用来预测未来可能发生的事件，通过观察数据了解事件发生的因果。而大数据时代，因果关系不再那么重要了，因为数据量庞大，人们更多是关注事物的相关性，比如淘宝购物中推送与你购买了同商品的人又买了其他什么商品的消息，而不是告诉你为什么其他人还购买了某件商品。



### 4.大数据关键技术

###### 数据采集

利用etl工具将分步的、异构数据源中的数据如关系数据、平面数据文件等，抽取到临时中间层后进行清洗、转换、集成，最后加载导数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础；或者也可以把实时采集的数据作为流计算系统的输入，进行实时处理分析。

###### 数据存储和管理

大数据存储与管理要用存储器把采集到的数据存储起来，建立相应的数据库，并进行管理和调用。重点解决复杂结构化、半结构化和非结构化大数据管理与处理技术。主要解决大数据的可存储、可表示、可处理、可靠性及有效传输等几个关键问题。开发可靠的分布式文件系统（DFS）、能效优化的存储、计算融入存储、大数据的去冗余及高效低成本的大数据存储技术；突破分布式非关系型大数据管理与处理技术，异构数据的数据融合技术，数据组织技术，研究大数据建模技术；突破大数据索引技术；突破大数据移动、备份、复制等技术；开发大数据可视化技术。

开发新型数据库技术，数据库分为关系型数据库、非关系型数据库以及数据库缓存系统。其中，非关系型数据库主要指的是NoSQL数据库，分为：键值数据库、列存数据库、图存数据库以及文档数据库等类型。关系型数据库包含了传统关系数据库系统以及NewSQL数据库。

开发大数据安全技术。改进数据销毁、透明加解密、分布式访问控制、数据审计等技术；突破隐私保护和推理控制、数据真伪识别和取证、数据持有完整性验证等技术。

###### 数据处理与分析

利用分布式并行编程模型和计算框架，结合机器学习和数据挖掘算法实现对海量数据的处理和分析;对分析结果进行可视化呈现，帮助人们更好地理解数据、分析数据。

###### 数据隐私和安全

在从大数据中挖掘潜在的巨大商业价值和学术价值的同时，构建隐私数据保护体系和数据安全体系，有效保护个人隐私和数据安全。

### 5.大数据计算模式

![image](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210907160809.png)

- 批处理计算

  主要解决针对大规模数据的批量处理，是数据分析工作中非常常见数据处理技术。

  MapReduce**并行执行大规模数据处理任务**，1TB以上的数据量。将并行计算过程抽象为两个函数Map和Reduce。
  Spark**启动内存分布数据集，可以进行交互式查询、优化迭代工作负载**。

- 流计算

  **流数据**是大数据分析中的重要数据类型,流数据是指**在时间分布和数据上无限的一系列动态数据集合**,数据的价值随着时间的流逝而降低。因此必须采用实时计算的方式给出秒级响应。

  第一类:商业级的流计算平台，IBM StreamBase
  第二类:开源流计算框架，Twitter Storm，Yahoo S4，Spark Streaming
  第三类:支持自身业务开发的流计算框架，Facebook Puma，百度Dstream，淘宝银河流数据处理平台

- 图计算

  许多数据是以大规模图和网络的形式呈现，MapReduce**不适用来解决大规模图计算问题**。
  Pregel是一种基于BSP模型实现的并行图形处理系统,主要用于图遍历、最短路径等。
  代表性的有Facebook针对pregel的开源实现Giraph，Spark下的GraphX,图数据处理系统PowerGraph。

- 查询分析计算

  Google公司开发的Dremel是一种**可扩展的、交互式的实时查询系统**，几秒内完成万亿张表的聚合查询，2-3s完成PB级别数据查询。
  Cloudera公司参考Dremel系统开发了实时查询引|擎Impala,能够查询存储在HDFS和Hbase中PB级大数据。

![image-20210914153905172](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210914153908.png)

### 6.大数据产业

大数据产业是指一切与支撑大数据组织管理和价值发现相关的企业经济活动的集合。

1. IT基础设施层
2. 数据源层
3. 数据管理层
4. 数据分析层
5. 数据平台层
6. 数据应用层



### 7.大数据与云计算、物联网的关系

相辅相成，既有联系又有区别。

#### 1.云计算

###### 什么是云计算？

通过整合、管理、调配分布在网络各处的计算资源,通过互联网以统一界面、同时向大量的用户提供服务。

云计算实现了通过网络提供可伸缩的、廉价的分布式计算能力，用户只需要在具备网络接入条件的地方，就可以随时随地获得所需的各种I资源。

![image-20210914163335502](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210914163335.png)

![image-20210914161251567](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210914161251.png)

###### 云计算分类

按照使用范围：

**共有云，私有云，混合云**

遵循的原则：

- Iaas (**基础设施即服务**) : 消费者通过Internet可得到完善的计算机基础设施,企事业单位不用建设机房,购买服务器等设备。
- Paas (**平台即服务**) :用户可以通过云计算服务商提供的平台开发或者运行软件。
- Saas (**软件即服务**) : 通过Internet提供软件服务,用户无需购买软件。

###### 云计算关键技术对比

![image-20210914160101458](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210914160101.png)

**云计算的关键技术包括 :虚拟化、 分布式存储、 分布式计算、多租户。**

- 虚拟化

  虚拟化技术是云计算基础架构的基石。是讲一台计算机虚拟为多台逻辑计算机，每个逻辑计算机可以在相互独立的空间运行。
  虚拟化的资源可以是硬件，也可以是软件。硬件可以让cpu、内存、磁盘、I/O等变成动态管理资源池。软件上, Vmware、Virtualbox、 Hyper-V都是典型的虚拟化技术。

- 分布式存储

  GFS——HDFS

  BigTable——HBase

- 分布式计算

  MapReduce

- 多租户

  目的在于使大量用户能够共享软硬件资源，提高资源利用率。

#### 2.物联网

###### 什么是物联网？

物联网是**物物相连的互联网**,是互联网的延伸,它利用局部网络或互联网等通信技术把传感器、控制器、机器、人员和物等通过新的方式连在一起。
物联网分为4层:

**感知层、网络层、处理层和应用层。**

###### 物联网关键技术

- 识别和感知技术(二维码、FRID、 传感器)、网络与通信技术、数据挖掘和融合技术。

- **网络与通信技术**，物联网中的网络和通信技术包括短距离无线通信技术和远程通信技术。

- 数据挖掘和融合技术，是物联网处理层需要解决的关键问题。



#### 3.大数据、物联网、云计算关系图

![image-20210914163626593](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210914163626.png)

### 8.Hadoop概述

#### 1.什么是Hadoop?

- Hadoop是Apache软件基金会旗下的一一**开源分布式计算平台**,为用户提供了系统**底层细节透明**的分布式基础架构。
- Hadoop是基于<u>Java</u>语言开发的,具有很好的**跨平台特性**,并且可以部署在廉价的计算机**集群**中。
- Hadoop的核心是**分布式文件系统HDFS** ( Hadoop Distributed File System )和**分布式并行计算MapReduce**。

- 大数据标准开源软件，在分布式环境下提供了海量数据的处理能力

#### 2.它的故事

​		Hadoop最初是由Apache Lucene项目的创始人Doug Cutting开发的文本搜索库。Hadoop源自始于2002年的Apache Nutch项目一个开源的网络搜索引擎并且也是Lucene项目的一部分。在2004年，Nutch项目也模仿GFS开发了自己的分布式文件系统<u>NDFS</u>( Nutch Distributed File System ) ,也就是<u>HDFS的前身</u>。同一年,谷歌公司又发表了另一篇具有深远影响的论文,阐述了MapReduce分布式编程思想。2005年，Nutch开源实现了谷歌的MapReduce到了2006年2月, Nutch中的NDFS和MapReduce开始独立出来,成为Lucene项目的一个子项目， 称为Hadoop ,同时，Doug Cutting加盟雅虎。2008年1月，Hadoop正式成为Apache顶级项目, Hadoop也逐渐开始被雅虎之外的其他公司使用。2008年4月，Hadoop打破世界纪录,**成为最快排序1TB数据的系统**。**它采用一个由910个节点构成的集群进行运算,排序时间只用了209秒！**在2009年5月，Hadoop更是把**1TB数据排序时间缩短到62秒**。Hadoop从此名声大震,迅速发展成为大数据时代最具影响力的开源分布式开发平台，并**成为事实上的大数据处理标准**。



#### 3.特性

- 高可靠
- 高效
- 高扩展
- 高容错
- 成本低
- 运行在linux上
- 支持多种编程语言
- ......

#### 4.版本

![image-20210923103649772](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210923103651.png)

**现在学习以第2版为主。**

商业化版本

- Cloudera ( CDH : Cloudera Distribution Hadoop )
- Hortonworks
- MapR

选择上需要考虑的因素：

- 是否开源
- 是否有稳定版
- 是否经实践检验
- 是否有强大的社区支持
- ......

### 9.Hadoop生态

![image-20210923105924146](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20210923105932.png)

- HDFS 分布式文件系统,处理超大规模、流式处理、部署廉价。
- HBase高可靠、高性能、可伸缩、实时读写、分布式列式数据库。
- MapReduce并行处理框架
- Hive数据仓库工具,对数据集进行整理、特殊查询和分析存储。
- Pig是一种数据流语言和运行环境,适合使用Hadoop平台查询半结构化数据集。
- Mahout Apache软件基金下的一个开源项目,提供一些可扩展的机器学习领域经典算法的实现。
- Zookeeper针对google Chubby的开源实现，是高效和可靠的协同工作系统。
- Flume高可用、高可靠、分布式的海量日志采集、聚合和传输的系统。
- Sqoop主要用来在Hadoop和关系数据库之间交换数据。
- Ambari是基于Web的工具,支持Apache Hadoop集群的安装、部署配置和管理。

### 10.Hadoop安装与使用

#### 1.准备工作

1. 安装平台Linux平台

2. 创建Hadoop用户(*)

3. Java的安装

4. SSH免密登录

   为什么？

   **Hadoop名称节点(NameNode)需要启动集群中所有机器的Hadoop守护进程，这个过程需要通过SSH登录来实现。Hadoop并没有提供SSH输入密码登录的形式，因此，为了能够顺利登录每台机器，需要将所有机器配置为名称节点可以无密码登录它们。**

   > 提示：提升为超级用户
   >
   > sudo usermod -G sudo zhangyu

5. 安装Hadoop

#### 2.Hadoop安装方式

- 单机模式:  Hadoop默认模式为非分布式模式(本地模式)， 无需进行其他配置即可运行。**非分布式即单Java进程**,方便进行调试
- 伪分布式模式:  Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的Java进程来运行，**节点既作为NameNode也**
  **作为DataNode ,同时,读取的是HDFS中的文件**
- 分布式模式: 使用**多个节点构成集群**环境来运行Hadoop

###### 1.单机和伪分布式安装方式

1. 如果系统是Linux，请参照下面给出的教程进行安装：

   推荐这个：[**Hadoop安装配置简略教程_厦大数据库实验室博客 (xmu.edu.cn)**](http://dblab.xmu.edu.cn/blog/install-hadoop-simplify/)

   在Ubuntu系统上安装Hadoop请参考：
   （1）《大数据技术原理与应用（第2版）》教材请参考： [Hadoop安装教程-单机-伪分布式配置-Hadoop2.6.0(2.7.1)-Ubuntu14.04(16.04)](http://dblab.xmu.edu.cn/blog/install-hadoop/)
   （2）《大数据技术原理与应用（第3版）》教材（已经在2020年12月出版，[教材官网](http://dblab.xmu.edu.cn/post/bigdata3)）请参考：[Hadoop安装教程_单机/伪分布式配置_Hadoop3.1.3/Ubuntu18.04(16.04)](http://dblab.xmu.edu.cn/blog/2441-2/)

   在CentOS系统上安装Hadoop请参考：
   [Hadoop安装教程-伪分布式配置-CentOS6.4-Hadoop2.6.0](http://dblab.xmu.edu.cn/blog/install-hadoop-in-centos/)

   需要注意以下几点：
   系统用户名使用hadoop
   不要修改/etc/hosts 默认的localhost地址，如果已经修改请重新把127.0.0.1映射到localhost

2. 如果系统是Mac，请参照下面给出的链接进行安装：
   [Mac 安装Hadoop教程-单机-伪分布式配置](http://dblab.xmu.edu.cn/blog/820-2/)

###### 2.分布式安装方式

（1）在集群上分布式安装Hadoop，请参考：
[Hadoop集群安装配置教程_Hadoop2.6.0_Ubuntu/CentOS](http://dblab.xmu.edu.cn/blog/install-hadoop-cluster/)

（2）使用Docker搭建Hadoop分布式集群，请参考实验室博客文章《[使用Docker搭建Hadoop分布式集群](http://dblab.xmu.edu.cn/blog/1233/)》。

## 11.分布式文件系统HDFS

#### 1.什么是分布式文件系统？

###### 1.计算机集群结构

- 分布式文件系统把文件分布存储到对各计算机节点上，成千上万的计算机节点构成计算机集群。
- 与之前使用多个处理器和专用高级硬件的**并行化处理装置**不同的是：
  - 目前分布式文件系统采用的计算机集群，都是由普通硬件构成的，这就大大降低了硬件开销。

![image-20211012144653616](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211012144653.png)



###### 2.分布式文件系统结构

- 物理结构：

  - 计算机集群中的多个节点构成的。这些节点分为两类。一类为**主节点（Master Node）**或者被称为**名称节点（NameNode）**；另一类叫**从节点（Slave Node）**或者也被称为**数据节点（DataNode）**。
  - 名称节点负责文件和目录的创建、删除和重命名等，同时管理着数据节点和文件块的映射关系。
  - 数据节点负责数据的存储和读写，以及名称节点的命令。

- 逻辑结构：

  ![image-20211012145454393](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211012145454.png)

###### 3.设计需求

1. 透明性
2. 并发控制
3. 可伸缩性
4. 容错性
5. 安全性
6. 。。。

#### 2.HDFS概述

HDFS开源实现了GFS的基本思想，HDFS原来是Apache Nutch搜索引擎的一部分，后来独立作为Apache子项目，并和MapReduce一起成为Hadoop的核心组成部分。

1. **HDFS的优势**：
   - 兼容廉价的硬件设备
   - 流数据读写
   - 大数据集
   - 简单的文件模型
   - 强大的跨平台兼容性
2. **HDFS的局限性：**
   - *<u>不适合低延迟的数据访问</u>*
   - <u>*无法高效存储大量小文件*</u>
   - *<u>不支持多用户写入及任意修改文件</u>*

##### 1.什么是 **块**？

> 在传统的文件系统中，为了提高磁盘读写效率，一般以数据块为单位。

![image-20211012150656361](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211012150656.png)

对于HDFS中，默认一个块是64MB，一个文件被分成多个块，以块作为**存储单位**，块的大小**远远大于**普通文件系统，**降低了单位数据的寻址开销**。

###### 好处有哪些？

- **支持大规模文件存储：**

  文件以块为单位进行存储，一个大规模文件可以被拆分成若干个文件块，不同的文件块可以被分发到不同的节点上，因此，一个文件的大小不会受到单个节点的存储容量限制，可以远远大于网络中任意节点的存储容量。

- **简化系统设计：**

  - 简化存储管理，因为文件块大小是固定的，这样可以很容易的计算出一个节点可以存储多少文件块。

  - 方便**元数据**的管理，元数据不需要和文件块一起存储，可以由其他系统负责管理元数据。

    > **元数据解释：**
    >
    > 元数据被定义为：**描述数据的数据，对数据及信息资源的描述性信息**。
    >
    > 元数据（Metadata）是描述其它数据的数据（data about other data），或者说是用于提供某种资源的有关信息的结构数据（structured data）。元数据是描述信息资源或数据等对象的数据，其使用目的在于：识别资源；评价资源；追踪资源在使用过程中的变化；实现简单高效地管理大量网络化数据；实现信息资源的有效发现、查找、一体化组织和对使用资源的有效管理。 元数据的基本特点主要有：
    >
    > a）元数据一经建立，便可共享。元数据的结构和完整性依赖于信息资源的价值和使用环境；元数据的开发与利用环境往往是一个变化的分布式环境；任何一种格式都不可能完全满足不同团体的不同需要；
    >
    > b）元数据首先是一种编码体系。元数据是用来描述数字化信息资源，特别是网络信息资源的编码体系，这导致了元数据和传统数据编码体系的根本区别；元数据的最为重要的特征和功能是为数字化信息资源建立一种机器可理解框架。

- **适合数据备份：**

  每个文件块都可以冗余存储到多个节点上，大大提高了系统的容错性和可用性。

##### 2.**名称节点和数据节点**

![image-20211012153029793](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211012153029.png)

###### 1.名称节点

它负责管理分布式文件系统的**命名空间(NameSpace)**,保存两个核心的数据结构，即`FsImage`和`EditLog`。

> 分布式文件系统的命名空间：目录、文件、块

- FsImage: 用于维护文件系统树以及文件树中所有文件和文件夹的元数据。

  > Fslmage文件详细解释：
  >
  > - Fslmage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息:文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据
  > - Fslmage文件没有记录文件包含哪些块以及每个块存储在哪个数据节点。而是由名称节点把这些映射信息保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。

- EditLog: 操作日志文件，记录了所有针对文件的创建、删除、重命名等操作。

**名称节点记录了每个文件中各个块所在的数据节点的位置信息，但是并不持久化存储这些信息，而是在系统每次启动时扫描所有数据节点重构得到这些信息。**

![image-20211012154449748](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211012154449.png)

###### 执行时名称节点怎样起作用的？

1. 启动时，它会将FsImage文件中的内容加载到内存中，然后执行EditLog文件中的各项操作，使得内存中的元数据和实际的同步。

2. 在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件。

3. 名称节点启动成功并进入正常状态后，**HDFS中的更新操作会重新写到EditLog文件**，而不是直接写FsImage。

   > 因为FsImage文件一般都很大(GB级别），如果所有的更新操作都往FsImage文件中添加，那么系统运行的十分缓慢。相对而言，EditLog通常会远小于FsImage，更新操作写入到EditLog是非常高效的。



###### 2.数据节点

数据节点(DataNode )是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的**存储和检索**，**并且向`名称节点`==定期发送自己所存储的块的列表==**。

##### 3.**第二名称节点**

>  名称节点运行期间EditLog不断变大的问题？

在名称节点运行期间，HDFS会不断发生更新操作，并且所有更新操作都是直接写到EditLog中，久而久之，EditLog文件将会变得很大。

虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将FsImage里面的所有内容映像到内存中，然后再一条一条地执行EditLog中的记录，当EditLog文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内**HDFS系统处于安全模式**，一直无法对外提供写操作，影响了用户的使用。

**怎么解决呢？**

使用==第二名称节点（SecondaryNameNode）==！

- 可以完成**EditLog与FsImage的合并操作**，减小EditLog文件大小，缩短名称节点重启时间。
- 可以作为名称节点的“检查点”，保存名称节点中的元数据信息。

###### 1.**EditLog与FsImage的合并操作**

![image-20211012160145502](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211012160145.png)

1. SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件editLog.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别,
2. SecondaryNameNode将NameNode上FsImage和EditLog文件拉回到本地，再加载到内存中;
3. 逐条执行EditLog文件中的各项更新操作，使得内存中的Fslmage保持最新;这就是EditLog和Fslmage文件合并
4. 将新的Fslmage发送到NameNode节点上.
5. NameNode将从第二名称节点接收到的新的Fslmage替换旧的Fslmage文件,同时用EditLog.new去替换EditLog文件，通过这个过程EditLog就变小了。

###### 2.作为名称节点的检查点

第二名称节点会定期和名称节点通信，从这个角度来讲，第二名称节点相当于名称节点的检查点，周期性的备份名称节点中的源数据信息，当**名称节点发生故障时，就可以用第二名称节点记录的源数据信息进行恢复。但是会丢失一部分更新操作。**

在HDFS的设计中，也并不支持系统直接切换到第二名称节点，第二名称节点**只是起到了名称节点检查点作用，并不能起到热备份作用。**

#### 3.HDFS结构

##### 1.概述

HDFS采用**主从结构模型**，一个HDFS集群包括**一个名称节点和若干个数据节点**。

**名称节点**作为中心服务器，**负责管理文件系统的命名空间及客户端对文件的访问**。

数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。**每个==数据节点的数据==实际上是保存在==本地Linux文件系统中==的。**

![image-20211019145218429](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211019145218.png)

HDFS采用Java语言开发，任何支持JVM的机器均可部署为名称节点和数据节点。**HDFS集群中只有唯一一个名称节点。**

##### 2.HDFS命名空间管理

HDFS的命名空间包含**目录、文件和块。**

**命名空间管理**是指：

- HDFS中目录文件和块做类似文件系统的创建、修改、删除等基本操作。

HDFS集群中只有一个命名空间！！！并且只有唯一名称节点，该节点是对命名空间进行管理的。

HDFS使用的是**传统的分级文件体系**，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件,在目录间转移文件,重命名文件等。

##### 3.通信协议

HDFS的通讯协议基于TCP/IP协议。

- **客户端和名称节点**：
  - 客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互。
- **名称节点和数据节点**：
  - 数据节点协议进行交互
- **客户端与数据节点**：
  - 通过RPC实现交互，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求。

##### 4.客户端

HDFS客户端是一个库，提供了HDFS文件系统接口，这些接口隐藏了HDFS实现中的大部分复杂性。

客户端支持打开、读取、写入等常见的操作，提供了两种方式：

- 类似Shell的命令行方式来访问HDFS的数据

- HDFS提供了Java API,作为应用程序客户端编程接口。

##### 5.局限性

 HDFS由于设置了唯一一个名称节点，虽然大大简化了系统的设计，但也导致了一些局限性：

（**唯一名称节点导致的局限性）**：

1. **命名空间的限制**: 名称节点是保存在内存中的,因此,名称节点能够容纳的对象(文件、块)的个数会受到内存空间大小的限制。
2. **性能的瓶颈**: 整个分布式文件系统的吞吐量,受限于单个名称节点的吞吐量。
3. **隔离问题**: 由于集群中只有一个名称节点,只有一个命名空间，因此,无法对不同应用程序进行隔离。
4. **集群的可用性**: 一旦这个唯一 的名称节点发生故障,会导致整个集群变得不可用。

#### **4.存储原理**

##### 1.数据的冗余存储

为了保证系统的容错性和可用性，HDFS采用了**多副本方式对数据进行冗余存储**,通常一个数据块的多个副本会被分布到**不同的数据节点**上，这种多副本方式具有以下几个优点。

- 加快数据传输速度

- 容易检查数据错误

- 保证数据可靠性

  ![image-20211026150106330](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211026150106.png)

##### 2.数据存取策略

###### 1.存

第一个副本：集群内发起写操作，放置在**上传文件**的==数据节点==上；如果是集群外进行提交的话，则会**随机挑选一台磁盘不太满、CPU不太忙的节点**上。

第二个副本：放置在与第一个副本**不同的机架的节点**上。

第三个副本：**与第一个副本相同机架的其它节点上。**

更多副本：随机节点位置上。

###### 2.取

**调用API的方式确定所属机架ID！！！**

当客户端读取数据时,**从名称节点获得数据块不同副本的存放位置列表**,列表中包含了**副本所在的数据节点,**可以调用API来确定客户端和这些数据节点所属的机架ID，当发现某个数据块副本对应的机架ID和客户端对应的机架ID**相同**时,就优先选择该副本读取数据,**如果没有发现,就随机选择一个副本读取数据。**

###### 3.复制

- **流水线复制策略，效率高。**

  ![image-20211026152644437](https://gitee.com/luoqianyi/static-image/raw/master/%E5%9B%BE%E5%BA%8A/20211026152644.png)

- 当client向 HDFS 文件写入数据的时候。一開始是写到本地暂时文件里。

- 假设该文件的副本系数设置为 3 ，当**本地暂时文件累积到一个数据块的大小**时，client会从 Namenode **获取一个 Datanode 列表用于存放副本。**然后client開始向第一个Datanode数据传输，第一个 Datanode 一小部分一小部分 (4 KB) 地接收数据，将**每一部分写入本地仓库。并同一时候传输该部分到列表中第二个 Datanode 节点**。第二个 Datanode 也是这样，一小部分一小部分地接收数据，写入本地仓库。并同一时候传给第三个 Datanode 。

- 最后，第三个 Datanode 接收数据并存储在本地。因此，Datanode 能流水线式地从前一个节点接收数据。并同一时候转发给下一个节点，数据以流水线的方式从前一个Datanode拷贝到下一个Datanode。

##### 3.数据错误与恢复

HDFS具有较高的容错性，可以兼容廉价的硬件，他把硬件出错看作一种常态，但是不是异常，并设计了相应机制数据错误和进行自动恢复，主要包括3种情形：

- **名称节点出错**
- **数据节点出错**
- **数据出错**

###### 1.名称节点出错

名称节点保存了所有的元数据信息,最核心数据结构是FsImage和Editlog ,如果这两个文件发生损坏,那么整个HDFS实例将失效。

1. **把名称节点上的元数据信息同步存储到其他文件系统;**
2. **运行第二名称节点,当名称节点宕机时,仍然会丢失部分数据。结合使用,将1中备份的元数据信息放到第二名称节点进行恢复,第二名称节点充当名称节点。**

###### 2.数据节点出错

每个数据节点会**定期向名称节点发送"心跳”信息**,向**名称节点**报告自己的状态,当**数据节点发生故障**,或者**网络发生断网时,**名称节点就无法收到来自一些数据节点的心跳信息,这时,这些数据节点就会**被标记为"宕机”**，节点上面的所有数据都会被标记为**“不可读“**，**名称节点不会再给它们发送任何I/O请求**。

###### 3.数据出错

- 网络传输和磁盘错误等因素，都会造成数据错误。
- 客户端在读取到数据后,会采用md5和sha1对数据块进行校验，以确定读取到正确的数据。
- 在文件被创建时，客户端就会对每一个文件块进行信息摘录,并把这些信息写入到同一个路径的隐藏文件里面。
- 当客户端读取文件的时候，会先读取该信息文件，然后,利用该信息文件对每个读取的数据块进行校验,如果校验出错，客户端就会请求到另外一个数据节点读取该文件块,并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块。

#### 5.HDFS的Shell编程

基本上在HDFS系统下执行的命令与linux下的相同，只不过前面加上**hdfs dfs -**Linux的命令或者**hadoop dfs -{args}**或者**hadoop fs -{args}** 

如果想HDFS文件与宿主机系统文件进行互通，有以下命令不同：

- `hdfs dfs -put 宿主机文件/目录  HDFS目录下`  ：上传宿主机文件到HDFS系统

- `hdfs dfs -get HDFS系统目录/文件 宿主机目录/文件 ` ： 下载HDFS系统里的文件到宿主机下

- `hadoop dfs admin -help`  :查看dfs管理命令帮助

- `hdfs dfs -appendToFile 本地文件 HDFS文件 ` ：将本地文件内容追加到HDFS文件里

- `hdfs dfs -rmr HDFS系统目录/文件` :删除hdfs系统下的文件或目录

- `hdfs dfs -touchz HDFS文件`：创建HDFS的文件

- `hdfs dfs -moveFromLocal 本地文件 HDFS目录下`：把指定的本地文件移动到HDFS系统指定的位置。

  

